N <- length(birth1) + length(birth2)
p_grid <-seq(from =0, to = 1, len =1000)
prob_p <- rep(1,1000)
prob_data <- dbinom(W,N,prob=p_grid)
posterior <-prob_data * prob_p
posterior <- posterior / sum(posterior)
# 3H2
# Sample probabilities from posterior distribution:
samples <- sample (p_grid, prob = posterior, size =1e4, replace =TRUE)
# 3H3
# Simulate births using sampled probabilities as simulation input, and check if they allign with real value.
simulated_births <- rbinom(n = 1e4, size = N, prob = samples)
rethinking::dens(simulated_births,show.PI = 0.95)
abline(v=W, col="red")
title("Simulated amount of boys in 200 births - red line is real value")
simulated_first_births <- rbinom(n = 1e4, size = length(birth1), prob = samples)
W1 <- sum(birth1)
rethinking::dens(simulated_first_births,show.PI = 0.95)
abline(v=W1, col="red")
n_first_born_girls <- -sum(birth1-1)
simulated_birth_after_girl <- rbinom(1e4, size = n_first_born_girls, prob = samples) # Simulate boys born after a girl
W2 <- sum(birth2[birth1 == 0]) # Get number of boys born after a girl
rethinking::dens(simulated_birth_after_girl,show.PI = 0.95)
abline(v=W2, col="red")
# Number of students
n <- 1000
# Simulate students
lecture_attendance <- rnorm(n)
happiness <- rnorm(n, lecture_attendance)
grade <- rnorm(n, lecture_attendance)
# Put the data in a data frame
d <- data.frame(lecture_attendance, happiness, grade)
# Model 1: grade ~ happiness
m5.1.1 <- quap(
alist(
grade ~ dnorm(mu, sigma),
mu <- a + b_h * happiness,
a ~ dnorm(0, 0.5),
b_h ~ dnorm(0, 0.5),
sigma ~ dexp(1)
), data = d
)
# Model 2: grade ~ lecture_attendance
m5.1.2 <- quap(
alist(
grade ~ dnorm(mu, sigma),
mu <- a + b_la * lecture_attendance,
a ~ dnorm(0, 0.5),
b_la ~ dnorm(0, 0.5),
sigma ~ dexp(1)
), data = d
)
# Model 3: grade ~ happiness + lecture_attendance
m5.1.3 <- quap(
alist(
grade ~ dnorm(mu, sigma),
mu <- a + b_h * happiness + b_la * lecture_attendance,
a ~ dnorm(0, 0.5),
b_h ~ dnorm(0, 0.5),
b_la ~ dnorm(0, 0.5),
sigma ~ dexp(1)
), data = d
)
# Look at the parameter estimates
precis(m5.1.1)
precis(m5.1.2)
precis(m5.1.3)
n <- 1000
time_at_party <- rnorm(n) #
beers_drunk <- rnorm(n, time_at_party)
people_talked_to <- rnorm(n, time_at_party)  # Negative correlation with study_hours
chance_of_getting_friends <- rnorm(n, (people_talked_to - beers_drunk) / 2)
d <- data.frame(chance_of_getting_friends, beers_drunk, people_talked_to)
# Predict chance_of_getting_friends ~ beers_drunk
m5.2.1 <- quap(
alist(
chance_of_getting_friends ~ dnorm(mu, sigma),
mu <- a + b_b * beers_drunk,
a ~ dnorm(0, 0.5),
b_b ~ dnorm(0, 0.5),
sigma ~ dexp(1)
), data = d
)
# Predict chance_of_getting_friends ~ people_talked_to
m5.2.2 <- quap(
alist(
chance_of_getting_friends ~ dnorm(mu, sigma),
mu <- a + b_p * people_talked_to,
a ~ dnorm(0, 0.5),
b_p ~ dnorm(0, 0.5),
sigma ~ dexp(1)
), data = d
)
# Predict chance_of_getting_friends ~ beers_drunk + people_talked_to
m5.2.3 <- quap(
alist(
chance_of_getting_friends ~ dnorm(mu, sigma),
mu <- a + b_b * beers_drunk + b_p * people_talked_to,
a ~ dnorm(0, 0.5),
b_b ~ dnorm(0, 0.5),
b_p ~ dnorm(0, 0.5),
sigma ~ dexp(1)
), data = d
)
precis(m5.2.1)
precis(m5.2.2)
precis(m5.2.3)
data(foxes)
# Model 1: weight ~ area
m5H1.1 <- quap(
alist(
weight ~ dnorm(mu, sigma),
mu <- a + b_a * area,
a ~ dnorm(7, 3), # Google says foxes weigh 2-14 kg
b_a ~ dnorm(3, 3), # No idea about area but the data shows it is somewhere between 1 and 5
sigma ~ dexp(1)
), data = foxes
)
m5H1.2 <- quap(
alist(
weight ~ dnorm(mu, sigma),
mu <- a + b_g * groupsize,
a ~ dnorm(7, 3), # Google says foxes weigh 2-14 kg
b_g ~ dnorm(6, 3), # No idea about area but the data shows it is somewhere between 2-8
sigma ~ dexp(1)
), data = foxes
)
# Plot the results
weight.seq <- seq(from = min(foxes$weight), to = max(foxes$weight), length.out = 100)
mu <- link(m5H1.1, data = list(area = weight.seq))
mu.mean <- apply(mu, 2, mean)
mu.PI <- apply(mu, 2, PI, prob = 0.95)
plot(foxes$weight, foxes$area, col = col.alpha(rangi2, 0.5), xlab = "Weight", ylab = "Area")
lines(weight.seq, mu.mean)
shade(mu.PI, weight.seq)
mu2 <- link(m5H1.2, data = list(groupsize = weight.seq))
mu2.mean <- apply(mu2, 2, mean)
mu2.PI <- apply(mu2, 2, PI, prob = 0.95)
plot(foxes$weight, foxes$groupsize, col = col.alpha(rangi2, 0.5), xlab = "Weight", ylab = "Groupsize")
lines(weight.seq, mu2.mean)
shade(mu2.PI, weight.seq)
m5H2 <- quap(
alist(
weight ~ dnorm(mu, sigma),
mu <- a + b_a * area + b_g * groupsize,
a ~ dnorm(7, 3), # Google says foxes weigh 2-14 kg
b_a ~ dnorm(3, 2), # No idea about area but the data shows it is somewhere between 1-5
b_g ~ dnorm(6, 2), # No idea about area but the data shows it is somewhere between 2-8
sigma ~ dexp(1)
), data = foxes
)
precis(m5H2)
weight.seq <- seq(from = min(foxes$weight), to = max(foxes$weight), length.out = 100)
area_seq <- seq(from = min(foxes$area), to = max(foxes$area), length.out = 100)
groupsize_seq <- seq(from = min(foxes$groupsize), to = max(foxes$groupsize), length.out = 100)
pred_area_data <- data.frame(area = area_seq, groupsize = mean(foxes$groupsize))
pred_groupsize_data <- data.frame(area = mean(foxes$area), groupsize = groupsize_seq)
pred_area <- link(m5H2, data = pred_area_data)
pred_groupsize <- link(m5H2, data = pred_groupsize_data)
# Compute mean and intervals from the matrices
pred_area_mu <- apply(pred_area, 2, mean)
pred_area_PI <- apply(pred_area, 2, PI)
pred_groupsize_mu <- apply(pred_groupsize, 2, mean)
pred_groupsize_PI <- apply(pred_groupsize, 2, PI)
plot(NULL, xlim = range(area_seq), ylim = range(pred_area_PI),
xlab = "Territory area", ylab = "Predicted weight",
main = "Effect of Area (holding groupsize constant)")
lines(area_seq, pred_area_mu, lwd = 2)
shade(pred_area_PI, area_seq)
plot(NULL, xlim = range(groupsize_seq), ylim = range(pred_groupsize_PI),
xlab = "Groupsize", ylab = "Predicted weight",
main = "Effect of Groupsize (holding area constant)")
lines(groupsize_seq, pred_groupsize_mu, lwd = 2)
shade(pred_groupsize_PI, groupsize_seq)
m5H3.1 <- quap(
alist(
weight ~ dnorm(mu, sigma),
mu <- a + b_a * area + b_f * avgfood,
a ~ dnorm(7, 3), # Google says foxes weigh 2-14 kg
b_a ~ dnorm(3, 2), # No idea about area but the data shows it is somewhere between 1-5
b_f ~ dnorm(1, 1), # No idea about area but the data shows it is somewhere between 0-2
sigma ~ dexp(1)
), data = foxes
)
m5H3.2 <- quap(
alist(
weight ~ dnorm(mu, sigma),
mu <- a + b_a * area + b_g * groupsize + b_f * avgfood,
a ~ dnorm(7, 3), # Google says foxes weigh 2-14 kg
b_a ~ dnorm(3, 2), # No idea about area but the data shows it is somewhere between 1-5
b_g ~ dnorm(6, 2), # No idea about area but the data shows it is somewhere between 2-8
b_f ~ dnorm(1, 1), # No idea about area but the data shows it is somewhere between 0-2
sigma ~ dexp(1)
), data = foxes
)
precis(m5H3.1)
precis(m5H3.2)
pacman::p_load(dagitty,
ggdag)
dag <- dagitty('dag {
A[pos="1.000,0.500"]
F[pos="0.000,0.000"]
G[pos="2.000,0.000"]
W[pos="1.000,-0.500"]
A -> F
F -> G
F -> W
G -> W
}')
# Plot the DAG
ggdag(dag, layout = "circle")+
theme_dag()
# Fit a model to estimate the effect of area on avgfood
m5H4.1 <- quap(
alist(
avgfood ~ dnorm(mu, sigma),
mu <- a + b_a * area,
a ~ dnorm(1, 1), # We know there is likely food where foxes live, so let's bias towards positive.
b_a ~ dnorm(0, 1),  # We don't really know the effect of area on food.
sigma ~ dexp(1)
), data = foxes
)
precis(m5H4.1)
# Fit a model to estimate the effect of avgfood on weight
m5H4.2 <- quap(
alist(
weight ~ dnorm(mu, sigma),
mu <- a + b_f * avgfood,
a ~ dnorm(7, 3), # Google says foxes weigh 2-14 kg
b_f ~ dnorm(1, 1), # No idea about area but the data shows it is somewhere between 0-2
sigma ~ dexp(1)
), data = foxes
)
precis(m5H4.2)
# Fit a model to estimate the direct effect of avgfood on weight
# We stratify by gropusize.
m5H4.3 <- quap(
alist(
weight ~ dnorm(mu, sigma),
mu <- a + b_f * avgfood + b_g * groupsize,
a ~ dnorm(7, 3), # Google says foxes weigh 2-14 kg
b_f ~ dnorm(1, 1), # No idea about area but the data shows it is somewhere between 0-2
b_g ~ dnorm(6, 2), # No idea about area but the data shows it is somewhere between 2-8
sigma ~ dexp(1)
), data = foxes
)
precis(m5H4.3)
# Load data and standardize
data(WaffleDivorce)
d <- WaffleDivorce
# Standardize the data
d$D <- standardize(d$Divorce)
d$W <- standardize(d$WaffleHouses)
d$S <- d$South
d$M <- standardize(d$Marriage)
d$A <- standardize(d$MedianAgeMarriage)
# The chapter provides a DAG for this data:
waffle_dag <- dagitty("dag {
A -> D
A -> M -> D
A <- S -> M
S -> W -> D
}")
# Fix coordinates
coordinates(waffle_dag) <- list(x = c(A = 1, S = 1, M = 2, W = 3, D = 3),
y = c(A = 1, S = 3, M = 2, W = 3, D = 1))
# Plot the DAG
ggdag(waffle_dag, layout = "circle") +
theme_dag()
# Find the adjustment sets
adjustmentSets(waffle_dag, exposure = "W", outcome = "D")
# Model D ~ W + S
m6H1 <- quap(
alist(
D ~ dnorm(mu, sigma),
mu <- a + b_w * W + b_s * S,
a ~ dnorm(0, 0.2), # Everything is standardized
b_w ~ dnorm(0, 0.5), # Everything is standardized
b_s ~ dnorm(0, 0.5), # Everything is standardized
sigma ~ dexp(1) # sd must be positive
), data = d
)
precis(m6H1)
# Get the implied conditional independencies
impliedConditionalIndependencies(waffle_dag)
# Test A _||_ W | S
# A ~ S
m6H2.1 <- quap(
alist(
A ~ dnorm(mu, sigma),
mu <- a + b_s * S,
a ~ dnorm(0, 0.2), # Everything is standardized
b_s ~ dnorm(0, 0.5), # Everything is standardized
sigma ~ dexp(1) # sd must be positive
), data = d
)
# A ~ S + W
m6H2.2 <- quap(
alist(
A ~ dnorm(mu, sigma),
mu <- a + b_s * S + b_w * W,
a ~ dnorm(0, 0.2), # Everything is standardized
b_s ~ dnorm(0, 0.5), # Everything is standardized
b_w ~ dnorm(0, 0.5), # Everything is standardized
sigma ~ dexp(1) # sd must be positive
), data = d
)
precis(m6H2.1)
precis(m6H2.2)
# Test D _||_ S | A, M, W
# D ~ A + M + W
m6H2.3 <- quap(
alist(
D ~ dnorm(mu, sigma),
mu <- a + b_a * A + b_m * M + b_w * W,
a ~ dnorm(0, 0.2), # Everything is standardized
b_a ~ dnorm(0, 0.5), # Everything is standardized
b_m ~ dnorm(0, 0.5), # Everything is standardized
b_w ~ dnorm(0, 0.5), # Everything is standardized
sigma ~ dexp(1) # sd must be positive
), data = d
)
# D ~ A + M + W + S
m6H2.4 <- quap(
alist(
D ~ dnorm(mu, sigma),
mu <- a + b_a * A + b_m * M + b_w * W + b_s * S,
a ~ dnorm(0, 0.2), # Everything is standardized
b_a ~ dnorm(0, 0.5), # Everything is standardized
b_m ~ dnorm(0, 0.5), # Everything is standardized
b_w ~ dnorm(0, 0.5), # Everything is standardized
b_s ~ dnorm(0, 0.5), # Everything is standardized
sigma ~ dexp(1) # sd must be positive
), data = d
)
precis(m6H2.3)
precis(m6H2.4)
# Test M _||_ W | S
# M ~ S
m6H2.5 <- quap(
alist(
M ~ dnorm(mu, sigma),
mu <- a + b_s * S,
a ~ dnorm(0, 0.2), # Everything is standardized
b_s ~ dnorm(0, 0.5), # Everything is standardized
sigma ~ dexp(1) # sd must be positive
), data = d
)
# M ~ S + W
m6H2.6 <- quap(
alist(
M ~ dnorm(mu, sigma),
mu <- a + b_s * S + b_w * W,
a ~ dnorm(0, 0.2), # Everything is standardized
b_s ~ dnorm(0, 0.5), # Everything is standardized
b_w ~ dnorm(0, 0.5), # Everything is standardized
sigma ~ dexp(1) # sd must be positive
), data = d
)
precis(m6H2.5)
precis(m6H2.6)
d$South
rbeta(10, 1, 1)
# Load data and standardize
data(WaffleDivorce)
d <- WaffleDivorce
# Standardize the data
d$D <- standardize(d$Divorce)
d$W <- standardize(d$WaffleHouses)
d$S <- dd$South
# Load data and standardize
data(WaffleDivorce)
d <- WaffleDivorce
# Standardize the data
d$D <- standardize(d$Divorce)
d$W <- standardize(d$WaffleHouses)
d$S <- d$South
d$M <- standardize(d$Marriage)
d$A <- standardize(d$MedianAgeMarriage)
# The chapter provides a DAG for this data:
waffle_dag <- dagitty("dag {
A -> D
A -> M -> D
A <- S -> M
S -> W -> D
}")
# Fix coordinates
coordinates(waffle_dag) <- list(x = c(A = 1, S = 1, M = 2, W = 3, D = 3),
y = c(A = 1, S = 3, M = 2, W = 3, D = 1))
# Plot the DAG
ggdag(waffle_dag, layout = "circle") +
theme_dag()
# Find the adjustment sets
adjustmentSets(waffle_dag, exposure = "W", outcome = "D")
# Model D ~ W + S
m6H1 <- quap(
alist(
D ~ dnorm(mu, sigma),
mu <- a + b_w * W + b_s * S,
a ~ dnorm(0, 0.2), # Everything is standardized
b_w ~ dnorm(0, 0.5), # Everything is standardized
b_s ~ dnorm(0, 10), # Southernness is 0 or 1
sigma ~ dexp(1) # sd must be positive
), data = d
)
precis(m6H1)
# Get the implied conditional independencies
impliedConditionalIndependencies(waffle_dag)
# Test A _||_ W | S
# A ~ S
m6H2.1 <- quap(
alist(
A ~ dnorm(mu, sigma),
mu <- a + b_s * S,
a ~ dnorm(0, 0.2), # Everything is standardized
b_s ~ dnorm(0, 10), # Southernness is 0 or 1
sigma ~ dexp(1) # sd must be positive
), data = d
)
# A ~ S + W
m6H2.2 <- quap(
alist(
A ~ dnorm(mu, sigma),
mu <- a + b_s * S + b_w * W,
a ~ dnorm(0, 0.2), # Everything is standardized
b_s ~ dnorm(0, 10), # Southernness is 0 or 1
b_w ~ dnorm(0, 0.5), # Everything is standardized
sigma ~ dexp(1) # sd must be positive
), data = d
)
precis(m6H2.1)
precis(m6H2.2)
# Test D _||_ S | A, M, W
# D ~ A + M + W
m6H2.3 <- quap(
alist(
D ~ dnorm(mu, sigma),
mu <- a + b_a * A + b_m * M + b_w * W,
a ~ dnorm(0, 0.2), # Everything is standardized
b_a ~ dnorm(0, 0.5), # Everything is standardized
b_m ~ dnorm(0, 0.5), # Everything is standardized
b_w ~ dnorm(0, 0.5), # Everything is standardized
sigma ~ dexp(1) # sd must be positive
), data = d
)
# D ~ A + M + W + S
m6H2.4 <- quap(
alist(
D ~ dnorm(mu, sigma),
mu <- a + b_a * A + b_m * M + b_w * W + b_s * S,
a ~ dnorm(0, 0.2), # Everything is standardized
b_a ~ dnorm(0, 0.5), # Everything is standardized
b_m ~ dnorm(0, 0.5), # Everything is standardized
b_w ~ dnorm(0, 0.5), # Everything is standardized
b_s ~ dnorm(0, 0.5), # Everything is standardized
sigma ~ dexp(1) # sd must be positive
), data = d
)
precis(m6H2.3)
precis(m6H2.4)
# Test D _||_ S | A, M, W
# D ~ A + M + W
m6H2.3 <- quap(
alist(
D ~ dnorm(mu, sigma),
mu <- a + b_a * A + b_m * M + b_w * W,
a ~ dnorm(0, 0.2), # Everything is standardized
b_a ~ dnorm(0, 0.5), # Everything is standardized
b_m ~ dnorm(0, 0.5), # Everything is standardized
b_w ~ dnorm(0, 0.5), # Everything is standardized
sigma ~ dexp(1) # sd must be positive
), data = d
)
# D ~ A + M + W + S
m6H2.4 <- quap(
alist(
D ~ dnorm(mu, sigma),
mu <- a + b_a * A + b_m * M + b_w * W + b_s * S,
a ~ dnorm(0, 0.2), # Everything is standardized
b_a ~ dnorm(0, 0.5), # Everything is standardized
b_m ~ dnorm(0, 0.5), # Everything is standardized
b_w ~ dnorm(0, 0.5), # Everything is standardized
b_s ~ dnorm(0, 10), # Southernness is 0 or 1
sigma ~ dexp(1) # sd must be positive
), data = d
)
precis(m6H2.3)
precis(m6H2.4)
# Test M _||_ W | S
# M ~ S
m6H2.5 <- quap(
alist(
M ~ dnorm(mu, sigma),
mu <- a + b_s * S,
a ~ dnorm(0, 0.2), # Everything is standardized
b_s ~ dnorm(0, 10), # Southernness is 0 or 1
sigma ~ dexp(1) # sd must be positive
), data = d
)
# M ~ S + W
m6H2.6 <- quap(
alist(
M ~ dnorm(mu, sigma),
mu <- a + b_s * S + b_w * W,
a ~ dnorm(0, 0.2), # Everything is standardized
b_s ~ dnorm(0, 10), # Southernness is 0 or 1
b_w ~ dnorm(0, 0.5), # Everything is standardized
sigma ~ dexp(1) # sd must be positive
), data = d
)
precis(m6H2.5)
precis(m6H2.6)
